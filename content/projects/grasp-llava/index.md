---
title: Grasp-LLaVA
date: 2023-10-26
authors:
  - admin
links:
  - type: site
    url: https://github.com/pandas-dev/pandas
tags:
  - llm
  - vision
  - ml-systems
---

◦ Improved out-of-distribution grasp accuracy by 15% over YOLO, ViT, and CLIP by designing and fine-tuning a Vision
Language Model with LoRA. Grasp-LLaVA consists of CLIP vision encoder and Vicuna LLM for zero-shot grasp classification
using textual reasonings based on the shape and grasp feasibility of the object.
◦ Improved inference latency (2X) by designing an inference infrastructure to switch between the edge and cloud models
based on the calibrated confidence of the edge model’s predictions.
◦ Skills: PyTorch, LLaVA, VLM, LLM, LoRA
◦ Accpeted at CODES+ISSS 2025, and AIRC 2025

<!--more-->
